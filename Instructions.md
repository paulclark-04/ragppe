# MultiSummarizer - Instructions pour Agents IA

## üéØ Vue d'ensemble du projet
MultiSummarizer est un assistant IA EdTech pour le r√©sum√© multimodal de contenus √©ducatifs 
(PDF, vid√©o, audio, texte). L'objectif est de permettre aux √©tudiants et professionnels 
de synth√©tiser rapidement des informations √† partir de supports vari√©s.

## üìä Objectifs SMART
- Traiter 2+ formats (PDF, texte, audio/vid√©o) d'ici fin 2025
- G√©n√©rer des r√©sum√©s synth√©tiques (extractifs + abstractifs)
- Interface React/TailwindCSS + base Firebase
- Recherche par mots-cl√©s dans les r√©sum√©s
- Qualit√© √©valu√©e via tests utilisateurs (√©tudiants/enseignants)

## ‚öôÔ∏è Contraintes techniques
- Conformit√© RGPD (donn√©es √©ducation)
- Optimisation co√ªts API et latence
- Mod√®les open source privil√©gi√©s
- Architecture scalable et modulaire

## üèóÔ∏è Architecture RAG cible

### Pipeline de traitement
1. **Ingestion** : Upload fichier ‚Üí D√©tection type ‚Üí Routing
2. **Extraction** :
   - Audio/Vid√©o : Whisper (medium/turbo) ‚Üí transcription
   - PDF : PyMuPDF + Nougat (documents scientifiques) ‚Üí texte
   - Texte brut : passage direct
3. **Chunking intelligent** :
   - Chunks adaptatifs selon type de document
   - Pr√©servation du contexte business
   - Taille optimale pour fen√™tre contexte LLM
4. **Embedding & Indexation** :
   - Transformation en vecteurs (dense embeddings)
   - Stockage dans base vectorielle (FAISS/Pinecone/Milvus)
   - Orchestr√© par LlamaIndex
5. **Retrieval** :
   - Recherche s√©mantique (top-k documents)
   - Strat√©gie hybride : dense (s√©mantique) + sparse (BM25 pour exact match)
   - Re-ranking par pertinence contextuelle
6. **G√©n√©ration** :
   - LLM (Mistral Large pour co√ªt/souverainet√©, GPT-4/Claude si complexe)
   - Fusion informations texte + visuelles (architecture BridgeNet pour multimodal)
   - G√©n√©ration r√©sum√© + contenus p√©dagogiques (quiz, flashcards)
7. **Stockage r√©sultats** : Firestore (r√©sum√©s + m√©tadonn√©es)

### Stack technique
- **Back-end IA** : Python + FastAPI
- **Frameworks** : LlamaIndex (RAG), LangChain (orchestration), Haystack (production)
- **Mod√®les** : Whisper, PyMuPDF, Mistral Large, GPT-4, Claude
- **Front-end** : React + TailwindCSS
- **BDD** : Firebase (Firestore + Storage + Auth)
- **H√©bergement** : AWS (Lambda pour serverless, EC2 pour GPU)

## üõ†Ô∏è Directives de d√©veloppement RAG

### Principes d'architecture
‚úÖ **Architecture modulaire (microservices)** :
   - Service Auth, Upload, Transcription, Extraction, Embedding, Summarization, Search, API
   - Communication via queues (RabbitMQ/AWS SQS)
   - Conteneurisation Docker + orchestration Kubernetes

‚úÖ **Optimisation du pipeline** :
   - Chunking adaptatif selon type document (acad√©mique vs g√©n√©ral)
   - Indexation hi√©rarchique pour requ√™tes multi-niveaux
   - Retrieval hybride (semantic + keyword)
   - Query expansion automatique via embeddings
   - Feedback loop pour apprentissage continu

‚úÖ **Gestion du contexte** :
   - Contexte maximal : respecter fen√™tres LLM (32k-128k tokens selon mod√®le)
   - Compression contextuelle pour √©viter retrieval noise
   - Prompts dynamiques adapt√©s utilisateur + contexte business
   - Cross-attention mechanisms pour alignement retrieved data ‚Üî query

### Structure du prompt RAG (√† impl√©menter)
Template prompt RAG optimal
prompt_template = """
R√¥le : Tu es un assistant p√©dagogique expert en synth√®se de contenus √©ducatifs.

Instructions strictes :

- Utilise UNIQUEMENT les informations du contexte fourni ci-dessous
- Si la r√©ponse n'est pas dans le contexte, indique-le clairement
- Ne jamais inventer d'informations
- Cite les sources (extraits de documents) quand pertinent
- Adapte le niveau de d√©tail selon le profil utilisateur (√©tudiant/enseignant)

Contexte :
{context}

Question utilisateur :
{query}

R√©ponse (structur√©e, claire, avec citations) :
"""
### Gestion des embeddings
**Strat√©gie hybride dense + sparse**
from sentence_transformers import SentenceTransformer
from rank_bm25 import BM25Okapi

**Dense : embeddings s√©mantiques**
dense_model = SentenceTransformer('all-MiniLM-L6-v2')
dense_embeddings = dense_model.encode(chunks)

**Sparse : BM25 pour mots-cl√©s exacts**
bm25 = BM25Okapi(tokenized_chunks)

**Fusion des r√©sultats (weighted scoring)**
def hybrid_retrieval(query, top_k=5):
dense_scores = semantic_search(query)
sparse_scores = bm25.get_scores(tokenize(query))
combined = 0.7 * dense_scores + 0.3 * sparse_scores
return top_k_results(combined)

### Flux de traitement (code FastAPI)
app/main.py - Structure FastAPI
from fastapi import FastAPI, UploadFile
from services import transcription, extraction, summarization

app = FastAPI()

@app.post("/api/upload")
async def upload_file(file: UploadFile):
# 1. Stockage Firebase Storage
file_url = await storage.save(file)

# 2. D√©tection type et routing
file_type = detect_type(file)

# 3. Extraction selon type
if file_type == "audio/video":
    text = await transcription.whisper_transcribe(file_url)
elif file_type == "pdf":
    text = await extraction.pymupdf_extract(file_url)
else:
    text = file.read()

# 4. Chunking + Embedding
chunks = chunk_text(text)
embeddings = create_embeddings(chunks)

# 5. Indexation vectorielle
await vector_db.index(embeddings, metadata)

# 6. G√©n√©ration r√©sum√© RAG
summary = await summarization.generate_rag(text, embeddings)

# 7. Stockage r√©sultats
await firestore.save(summary, metadata)

return {"status": "success", "summary_id": summary.id}

### M√©triques qualit√© √† impl√©menter
- **ROUGE scores** (ROUGE-1, ROUGE-2, ROUGE-L) pour r√©sum√©s texte
- **BLEU scores** pour coh√©rence
- **Retrieval precision@k** : pertinence top-k documents
- **Latence** : < 5s pour g√©n√©ration r√©sum√©
- **M-info** (Multimodal Information) pour contenus image+texte


## üîí Exigences s√©curit√© (CRITIQUE)

### Authentification & Autorisation
- Firebase Auth JWT obligatoire
- R√®gles Firestore : utilisateur acc√®de uniquement ses donn√©es
- Validation token c√¥t√© backend FastAPI

### RGPD
- Consentement explicite collecte donn√©es
- Droit √† l'effacement (suppression compl√®te sur demande)
- Portabilit√© donn√©es (export JSON)
- Chiffrement transit (HTTPS/TLS) + repos (Firebase/S3)

### Gestion secrets
- Variables environnement (.env)
- AWS Secrets Manager / HashiCorp Vault pour cl√©s API
- JAMAIS de cl√©s en dur dans le code

### Monitoring
- Logging structur√© JSON (INFO/WARNING/ERROR)
- M√©triques : latence, throughput, taux erreurs
- Alertes sur erreurs critiques
- Tracing distribu√© (Jaeger/AWS X-Ray)